{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c3127d0-db2b-4820-b0be-5c60efbe0f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "product_id        0\n",
      "product_name     16\n",
      "aisle_id          0\n",
      "department_id     0\n",
      "prices            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define the project folder path\n",
    "project_folder = r\"/Users/cem/Desktop/Data Immersion/Achievement 4_Project\"\n",
    "\n",
    "# Define the data folder path\n",
    "data_folder = os.path.join(project_folder, \"Data\", \"4.3_orders_products\")\n",
    "\n",
    "# Loading products.csv\n",
    "products_path = os.path.join(data_folder, \"products.csv\")\n",
    "df_prods = pd.read_csv(products_path, index_col=False)\n",
    "\n",
    "# Load orders.csv\n",
    "orders_path = os.path.join(data_folder, \"orders.csv\")\n",
    "df_ords = pd.read_csv(orders_path, index_col=False)\n",
    "\n",
    "# Checking for missing values in df_prods\n",
    "print(\"Missing values in each column:\")\n",
    "print(df_prods.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "029f3d52-86d5-46dc-8d8a-55c08290442a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 5\n"
     ]
    }
   ],
   "source": [
    "# Checking for duplicate rows\n",
    "print(\"Number of duplicate rows:\", df_prods.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad2a1b58-befb-4457-87a7-c5d3ec741d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing duplicate rows\n",
    "df_prods = df_prods.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "636e1a2b-f8ae-4be7-91bd-34d1b9cfcab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types:\n",
      "product_id         int64\n",
      "product_name      object\n",
      "aisle_id           int64\n",
      "department_id      int64\n",
      "prices           float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Checking data types\n",
    "print(\"Data types:\")\n",
    "print(df_prods.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a2ff6dd-45d1-4c15-9840-175eb7b2e262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative prices:\n",
      "Empty DataFrame\n",
      "Columns: [product_id, product_name, aisle_id, department_id, prices]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Checking for negative prices\n",
    "if 'prices' in df_prods.columns:\n",
    "    print(\"Negative prices:\")\n",
    "    print(df_prods[df_prods['prices'] < 0])\n",
    "else:\n",
    "    print(\"No 'prices' column found in df_prods.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f31e355-384d-4216-b732-3f35fce79d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_number</th>\n",
       "      <th>order_dow</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.421083e+06</td>\n",
       "      <td>3.421083e+06</td>\n",
       "      <td>3.421083e+06</td>\n",
       "      <td>3.421083e+06</td>\n",
       "      <td>3.421083e+06</td>\n",
       "      <td>3.214874e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.710542e+06</td>\n",
       "      <td>1.029782e+05</td>\n",
       "      <td>1.715486e+01</td>\n",
       "      <td>2.776219e+00</td>\n",
       "      <td>1.345202e+01</td>\n",
       "      <td>1.111484e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.875817e+05</td>\n",
       "      <td>5.953372e+04</td>\n",
       "      <td>1.773316e+01</td>\n",
       "      <td>2.046829e+00</td>\n",
       "      <td>4.226088e+00</td>\n",
       "      <td>9.206737e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.552715e+05</td>\n",
       "      <td>5.139400e+04</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>4.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.710542e+06</td>\n",
       "      <td>1.026890e+05</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.300000e+01</td>\n",
       "      <td>7.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.565812e+06</td>\n",
       "      <td>1.543850e+05</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>1.500000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.421083e+06</td>\n",
       "      <td>2.062090e+05</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>3.000000e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           order_id       user_id  order_number     order_dow  \\\n",
       "count  3.421083e+06  3.421083e+06  3.421083e+06  3.421083e+06   \n",
       "mean   1.710542e+06  1.029782e+05  1.715486e+01  2.776219e+00   \n",
       "std    9.875817e+05  5.953372e+04  1.773316e+01  2.046829e+00   \n",
       "min    1.000000e+00  1.000000e+00  1.000000e+00  0.000000e+00   \n",
       "25%    8.552715e+05  5.139400e+04  5.000000e+00  1.000000e+00   \n",
       "50%    1.710542e+06  1.026890e+05  1.100000e+01  3.000000e+00   \n",
       "75%    2.565812e+06  1.543850e+05  2.300000e+01  5.000000e+00   \n",
       "max    3.421083e+06  2.062090e+05  1.000000e+02  6.000000e+00   \n",
       "\n",
       "       order_hour_of_day  days_since_prior_order  \n",
       "count       3.421083e+06            3.214874e+06  \n",
       "mean        1.345202e+01            1.111484e+01  \n",
       "std         4.226088e+00            9.206737e+00  \n",
       "min         0.000000e+00            0.000000e+00  \n",
       "25%         1.000000e+01            4.000000e+00  \n",
       "50%         1.300000e+01            7.000000e+00  \n",
       "75%         1.600000e+01            1.500000e+01  \n",
       "max         2.300000e+01            3.000000e+01  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q2: Running df.describe() on df_ords\n",
    "df_ords.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e120e41f-b675-4db0-9759-6823291e1742",
   "metadata": {},
   "source": [
    "## Question 2: Analysis of df.describe() Output\n",
    "\n",
    "Since the numbers are very large and I couldn't find a way to convert them directly, I'm not sure how to read them. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8cbe0d22-968b-4e34-9a83-13e266b774fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id                    int64\n",
      "user_id                     int64\n",
      "eval_set                   object\n",
      "order_number                int64\n",
      "order_dow                   int64\n",
      "order_hour_of_day           int64\n",
      "days_since_prior_order    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Q3. Checking for mixed-type data in your df_ords dataframe.\n",
    "\n",
    "print(df_ords.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89234773-55e4-4d78-bd1c-9d17d55d8752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking column 'eval_set':\n",
      "eval_set\n",
      "<class 'str'>    3421083\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking object-type columns for mixed types\n",
    "for col in df_ords.columns:\n",
    "    if df_ords[col].dtype == 'object':\n",
    "        print(f\"\\nChecking column '{col}':\")\n",
    "        print(df_ords[col].apply(type).value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afc2f0b-892a-4347-9652-8c082b13645a",
   "metadata": {},
   "source": [
    "## Question 4: Mixed-Type Data\n",
    "\n",
    "After checking the df_ords dataframe for mixed-type data, only the eval_set column was identified as an object data type. \n",
    "\n",
    "However, upon inspecting its contents, all values in this column are of the same type: <class 'str'>. \n",
    "\n",
    "Therefore, no corrections are needed since there are no mixed types in this column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e4f06c2-1c32-479c-99b5-ffb19b039f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id                       0\n",
      "user_id                        0\n",
      "eval_set                       0\n",
      "order_number                   0\n",
      "order_dow                      0\n",
      "order_hour_of_day              0\n",
      "days_since_prior_order    206209\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Q5: Checking for missing values\n",
    "print(df_ords.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fbfd2a-69db-45d1-b1a9-a0d1dae5a136",
   "metadata": {},
   "source": [
    "## Question 5: Missing Values Check\n",
    "\n",
    "After checking for missing values in the df_ords dataframe, only the days_since_prior_order column was found to contain missing values. All other columns are complete.\n",
    "\n",
    "The missing values in days_since_prior_order likely correspond to customers' first-ever orders, for which there is no previous order to calculate the days since prior order. This is consistent with expectations and does not indicate an issue with the data.\n",
    "\n",
    "No additional action is required for these missing values, as they are a natural outcome of the dataset's structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d77fc327-f1d8-4560-8c15-5b4677bc67d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6: Addressing the missing values\n",
    "df_ords['days_since_prior_order'] = df_ords['days_since_prior_order'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c8980ae9-5cfc-4495-a6ef-cecd9cbd2a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id                  0\n",
      "user_id                   0\n",
      "eval_set                  0\n",
      "order_number              0\n",
      "order_dow                 0\n",
      "order_hour_of_day         0\n",
      "days_since_prior_order    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_ords.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acad7d5b-06a6-46e9-b1b1-15811eb00321",
   "metadata": {},
   "source": [
    "## Question 6: Handling Missing Values\n",
    "\n",
    "To handle the missing values in the days_since_prior_order column of the df_ords dataframe, I chose to fill them with 0. This is because missing values in this column most likely represent the customer's first order, for which there is no previous order to calculate the days since prior order. By filling these missing values with 0, we maintain the logical consistency of the data without introducing bias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f447701e-4cc3-43cf-8a60-57fa51c16a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows in df_ords: 0\n"
     ]
    }
   ],
   "source": [
    "# Q7: Checking for duplicate rows in df_ords\n",
    "print(\"Number of duplicate rows in df_ords:\", df_ords.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e774eb-e850-488f-8ec5-c8d4b09cc457",
   "metadata": {},
   "source": [
    "## Question 7: Checking for Duplicate Values\n",
    "\n",
    "After checking for duplicate rows in the df_ords dataframe, 0 duplicate rows were found.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2fd546c2-80da-464d-a8fe-3e02e5e767d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8: Removing duplicate rows in df_ords\n",
    "df_ords = df_ords.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4569e4d-1d5f-416c-9128-caa3dfad585d",
   "metadata": {},
   "source": [
    "## Question 8: Addressing Duplicate Values\n",
    "\n",
    "To address duplicate values in the df_ords dataframe, I removed duplicate rows using the drop_duplicates() method. \n",
    "\n",
    "This ensures that each order record is unique and prevents double-counting or skewed analysis results.\n",
    "\n",
    "This method is appropriate because duplicate rows could arise from repeated data entry or data ingestion errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6b88063-bf7f-4ac9-9a91-01bb6f131a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q9: Export final, cleaned dataframes\n",
    "prepared_data_folder = os.path.join(project_folder, 'Data', 'Prepared Data')\n",
    "\n",
    "# Export cleaned df_prods\n",
    "products_export_path = os.path.join(prepared_data_folder, \"products_checked.csv\")\n",
    "df_prods.to_csv(products_export_path, index=False)\n",
    "\n",
    "# Export cleaned df_ords\n",
    "orders_export_path = os.path.join(prepared_data_folder, \"orders_checked.csv\")\n",
    "df_ords.to_csv(orders_export_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef943479-f990-4a9f-8aec-82429eaee419",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
